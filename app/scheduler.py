# app/scheduler.py - ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð·Ð°Ð´Ð°Ñ‡ Ð´Ð»Ñ Barkery_bot
import asyncio
import os
import shutil
from datetime import datetime
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from app.config import settings
import logging

logger = logging.getLogger(__name__)

# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº
scheduler = AsyncIOScheduler()


def setup_backup_schedule():
    """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ñ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ"""
    try:
        # Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ð¾Ðµ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ðµ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² 4:00 Ð¿Ð¾ ÑÐµÑ€Ð±ÑÐºÐ¾Ð¼Ñƒ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
        scheduler.add_job(
            backup_database,
            CronTrigger(hour=4, minute=0, timezone=settings.timezone),
            id='daily_backup',
            name='Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ð¾Ðµ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ðµ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð‘Ð”',
            replace_existing=True
        )
        logger.info("âœ… Ð Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¾ (4:00 ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ð¾)")
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°: {e}")


def start_scheduler():
    """Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°"""
    if not scheduler.running:
        scheduler.start()
        logger.info("âœ… ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð·Ð°Ð´Ð°Ñ‡ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½")


def stop_scheduler():
    """ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°"""
    if scheduler.running:
        scheduler.shutdown()
        logger.info("âœ… ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð·Ð°Ð´Ð°Ñ‡ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½")


async def backup_database():
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð¿Ð¸Ð¸ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ"""
    try:
        source_db = "barkery.db"
        if not os.path.exists(source_db):
            logger.warning("âŒ Ð¤Ð°Ð¹Ð» Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
            return False

        # 1. Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ
        os.makedirs("backups", exist_ok=True)

        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° Ñ timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"barkery_backup_{timestamp}.db"
        local_backup_path = f"backups/{backup_filename}"

        # ÐšÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ñ„Ð°Ð¹Ð» Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾
        shutil.copy2(source_db, local_backup_path)
        logger.info(f"âœ… Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð°Ñ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð°Ñ ÐºÐ¾Ð¿Ð¸Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð°: {local_backup_path}")

        # 2. Ð£Ð´Ð°Ð»ÐµÐ½Ð½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ (Ð¸Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ñ - Ð¼Ð¾Ð¶Ð½Ð¾ Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð½Ð° S3, FTP Ð¸ Ñ‚.Ð´.)
        remote_success = await backup_to_remote_storage(local_backup_path, backup_filename)

        if remote_success:
            logger.info(f"âœ… Ð ÐµÐ·ÐµÑ€Ð²Ð½Ð°Ñ ÐºÐ¾Ð¿Ð¸Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð² ÑƒÐ´Ð°Ð»ÐµÐ½Ð½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ: {backup_filename}")
        else:
            logger.warning("âš ï¸ Ð ÐµÐ·ÐµÑ€Ð²Ð½Ð°Ñ ÐºÐ¾Ð¿Ð¸Ñ Ð½Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð² ÑƒÐ´Ð°Ð»ÐµÐ½Ð½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ")

        # 3. ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ð±ÑÐºÐ°Ð¿Ñ‹ (Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 7)
        await cleanup_old_backups()

        return True

    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð¿Ð¸Ð¸: {e}")
        return False


async def backup_to_remote_storage(local_path: str, filename: str):
    """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð¿Ð¸Ð¸ Ð² ÑƒÐ´Ð°Ð»ÐµÐ½Ð½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ"""
    try:
        # Ð˜Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ñ ÑƒÐ´Ð°Ð»ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ð°
        # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ Ð·Ð´ÐµÑÑŒ Ð±ÑƒÐ´ÐµÑ‚ ÐºÐ¾Ð´ Ð´Ð»Ñ S3, FTP, Google Drive Ð¸ Ñ‚.Ð´.

        # ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð´Ð»Ñ S3 (Ñ€Ð°ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐµ):
        # import boto3
        # s3 = boto3.client('s3')
        # s3.upload_file(local_path, 'your-bucket-name', f'backups/{filename}')

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ð¸Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ð°
        remote_dir = "remote_backups"
        os.makedirs(remote_dir, exist_ok=True)

        remote_path = f"{remote_dir}/{filename}"
        shutil.copy2(local_path, remote_path)

        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ ÑƒÑÐ¿ÐµÑ…
        file_size = os.path.getsize(remote_path) / 1024  # KB
        logger.info(f"ðŸ“ Ð£Ð´Ð°Ð»ÐµÐ½Ð½Ð°Ñ ÐºÐ¾Ð¿Ð¸Ñ: {remote_path} ({file_size:.1f} KB)")

        return True

    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ð¸ Ð² ÑƒÐ´Ð°Ð»ÐµÐ½Ð½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ: {e}")
        return False


async def cleanup_old_backups():
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ñ‹Ñ… ÐºÐ¾Ð¿Ð¸Ð¹"""
    try:
        # ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð±ÑÐºÐ°Ð¿Ð¾Ð²
        if os.path.exists("backups"):
            backup_files = sorted(
                [f for f in os.listdir("backups") if f.endswith(".db")],
                key=lambda x: os.path.getctime(os.path.join("backups", x))
            )

            if len(backup_files) > 7:
                for old_file in backup_files[:-7]:
                    os